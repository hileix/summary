# JS 中浮点数精度问题

为什么 0.1 + 0.2 = 0.30000000000000004？

JavaScript 中所有数字包括整数和小数都只有一种类型 — Number。它的实现遵循 `IEEE 754 标准`，使用 `64 位固定长度` 来表示，也就是标准的 double 双精度浮点数（相关的还有 float 32 位单精度）。

这样的 `存储结构` 优点是可以 `归一化处理整数和小数，节省存储空间`。

## 浮点数的运算

0.1 + 0.2 时发生了什么？

1. 首先 0.1 和 0.2 会转换为二级制的数。`浮点数用二进制表示时是无穷的`，所以会得到下面的数：

```
0.1 -> 0.0001 1001 1001 1001...(1100循环)
0.2 -> 0.0011 0011 0011 0011...(0011循环)
```

2. IEEE 754 标准的 64 位双精度浮点数的小数部分最多支持 53 位二进制位，所以两者相加之后得到二进制为：

```
0.01001100110011001100110011001100110011001100110011
```

3. 因浮点数小数位的限制而截断的二进制数字，再转换为十进制，就成了 0.30000000000000004。所以在进行算术计算时会产生误差。

总结：在十进制转换为二进制后，二进制数 `因为浮点数小数位的限制而截断了`。所以二进制计算得到的结果就有误差

## 解决方案

使用第三方库：

- [mathjs](https://github.com/josdejong/mathjs)
- [decimal.js](https://github.com/MikeMcl/decimal.js)

如果是金额的话，可以将单位转换为 `分`，然后通过分进行金额的计算，最后再除以 100 转回来。

# 参考

https://juejin.cn/post/6844903572979597319
https://github.com/camsong/blog/issues/9
